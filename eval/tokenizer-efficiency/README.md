The `get-tokenizer-efficiency.py` script will pull an chunk (`{lang}_part_00004`, chosen arbitrarily) from [uonlp/CulturaX](https://huggingface.co/datasets/uonlp/CulturaX) and use it to calculate English and Japanese tokenizer efficiency.

Prior results are cached in the json files, md has human readable tables.

|    | LLM               | Tokenizer                              |   Vocab Size |   Avg Char/Token |
|---:|:------------------|:---------------------------------------|-------------:|-----------------:|
|  0 | shisa-v1          | augmxnt/shisa-7b-v1                    |       120073 |          4.12321 |
|  1 | Jamba             | ai21labs/Jamba-v0.1                    |        65536 |          4.31269 |
|  2 | DBRX              | databricks/dbrx-instruct               |       100278 |          4.58203 |
|  3 | Swallow MX NVE    | tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1 |        32000 |          4.00856 |
|  4 | Yi 34B 200K       | 01-ai/Yi-34B-200K                      |        64000 |          4.18616 |
|  5 | Orion 14B         | OrionStarAI/Orion-14B-Base             |        84608 |          4.25367 |
|  6 | Cohere Command-R+ | CohereForAI/c4ai-command-r-plus        |       255000 |          4.45377 |
|  7 | Llama 3           | NousResearch/Meta-Llama-3-8B           |       128000 |          4.58694 |
|  8 | RakutenAI-7B      | Rakuten/RakutenAI-7B                   |        48000 |          4.00896 |
|  9 | Yi 1.5            | 01-ai/Yi-1.5-34B-Chat                  |        64000 |          4.18721 |
| 10 | Falcon 2          | tiiuae/falcon-11B                      |        65024 |          4.39006 |
| 11 | GPT-4             | Xenova/gpt-4                           |       100263 |          4.58203 |
| 12 | GPT-4o            | Xenova/gpt-4o                          |       200000 |          4.65736 |
| 13 | Gemma 7B          | google/gemma-7b                        |       256000 |          4.47085 |
| 14 | Stockmark 100B    | stockmark/stockmark-100b               |        60032 |          3.99234 |
| 15 | Microsoft Phi 3   | microsoft/Phi-3-medium-128k-instruct   |        32000 |          3.86401 |
|    | LLM               | Tokenizer                              |   Vocab Size |   Avg Char/Token |
|---:|:------------------|:---------------------------------------|-------------:|-----------------:|
|  0 | shisa-v1          | augmxnt/shisa-7b-v1                    |       120073 |         2.3074   |
|  1 | Jamba             | ai21labs/Jamba-v0.1                    |        65536 |         0.92805  |
|  2 | DBRX              | databricks/dbrx-instruct               |       100278 |         0.998234 |
|  3 | Swallow MX NVE    | tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1 |        32000 |         0.945937 |
|  4 | Yi 34B 200K       | 01-ai/Yi-34B-200K                      |        64000 |         0.832232 |
|  5 | Orion 14B         | OrionStarAI/Orion-14B-Base             |        84608 |         1.7117   |
|  6 | Cohere Command-R+ | CohereForAI/c4ai-command-r-plus        |       255000 |         1.64356  |
|  7 | Llama 3           | NousResearch/Meta-Llama-3-8B           |       128000 |         1.4549   |
|  8 | RakutenAI-7B      | Rakuten/RakutenAI-7B                   |        48000 |         1.6117   |
|  9 | Yi 1.5            | 01-ai/Yi-1.5-34B-Chat                  |        64000 |         0.831878 |
| 10 | Falcon 2          | tiiuae/falcon-11B                      |        65024 |         0.756638 |